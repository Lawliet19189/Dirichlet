{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regional-apollo",
   "metadata": {},
   "source": [
    "## In this notebook, I have highlited few of the approaches which I have tried, to learn the inverse of a reassigned spectogram algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-electricity",
   "metadata": {},
   "source": [
    "### Let's start with the reassigned Spectogram parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft, nperseg = 80, 80 \n",
    "window = \"hamming\"\n",
    "center = False # reassigned times are not alighned to the frame, so it's preferred to use center as False\n",
    "pad_mode = \"wrap\" # added for completeness, since we are not centering, there would be no padding used.\n",
    "win_length, hop_length = 80, 80//4\n",
    "fill_nan = True # returns bin freq and frame times instead of nan\n",
    "clip = False # since our objective is to recreate the signal, we would like to keep the freq and time that are beyond the bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-geography",
   "metadata": {},
   "source": [
    "### Few General design decisions across architecures \n",
    "+ MSE loss with mean reduction\n",
    "+ AdamW with no weight decay and with AMSGRAD\n",
    "+ Manual scheduler that reduces the learning rate when loss doesn't improve.\n",
    "+ Batch size of 1 with Gradient Accumulation of 128 steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-forward",
   "metadata": {},
   "source": [
    "### Approach 1: simple architecture\n",
    "\n",
    "+ The easiest way to approach is to feed all the information to the model and ask it figure out the mapping on it's own.\n",
    "+ this is what we do in this approach, where we feed the outputs of reassigned spectogram to our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, times, mags = librosa.reassigned_spectrogram(\n",
    "    signal, sr=16000, n_fft=80, \n",
    "    window=\"hamming\", center=True, \n",
    "    pad_mode=\"wrap\", win_length=80, \n",
    "    hop_length=80//4, fill_nan=True, \n",
    "    reassign_times=True, clip=False\n",
    ")\n",
    "\n",
    "Zxx = np.vstack((freq, times mags)) # (41*3, number_of_frames)\n",
    "\n",
    "# reshaping for CNN architecture\n",
    "Zxx = Zxx.reshape(1, 1, Zxx.shape[0], -1)\n",
    "X = torch.Tensor(Zxx).to(device)\n",
    "\n",
    "# passing it to our model\n",
    "out = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model architecture\n",
    "\n",
    "class flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(flatten, self).__init__()\n",
    "        pass\n",
    "    def forward(self, out):\n",
    "        return torch.swapaxes(out.squeeze(), 0, 1).flatten()  \n",
    "    \n",
    "# 80 -> n_fft, 123 -> 41 *3, 2-> hop_length/window_overlap\n",
    "model = nn.Sequential(\n",
    "   nn.Conv2d(1, 80, kernel_size=(123, 2), stride=1, bias=True),\n",
    "   nn.Dropout2d(p=0.3),\n",
    "   nn.BatchNorm2d(80),\n",
    "   nn.Conv2d(80, 20, kernel_size=(1, 1), stride=1, bias=True), # Acts as a linear layer\n",
    "   flatten()\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-terrorist",
   "metadata": {},
   "source": [
    "### Results\n",
    "+ The best train MSE loss we get is 2e-2, which is not enough to recreate the signal.\n",
    "+ As you can also observe, in the reassigned_spectrogram function, we used center as True, this is specifically to align with simple architecture of CNN. To make use of center as False, we have to pad and manipulate the signal appropriately. Instead of doing this workaround, we move to the next approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-strain",
   "metadata": {},
   "source": [
    "### Approach 2: unwrapping the tfr output\n",
    "\n",
    "+ In this approach, we try to focus on these things:\n",
    "    + increase the models capacity to learn by decreasing the complexity of the data\n",
    "        + Instead of passing padded redundant features in a time frame to the model, we remove the redundant values and provide less complex data.\n",
    "    + utilize center=False during reassign_spectogram process.\n",
    "    + Adapt the CNN architecture to the new less complex data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, times, mags = librosa.reassigned_spectrogram(\n",
    "    signal, sr=16000, n_fft=80, \n",
    "    window=\"hamming\", center=False, \n",
    "    pad_mode=\"wrap\", win_length=80, \n",
    "    hop_length=80//4, fill_nan=True, \n",
    "    reassign_times=True, clip=False\n",
    ")\n",
    "\n",
    "# unwraps (41, number_of_frames) -> (1, len(signal))\n",
    "freq = np.append(freq[:nfft//4, :-1], freq[:,-1])\n",
    "times = np.append(times[:nfft//4, :-1], times[:,-1])\n",
    "mags = np.append(mags[:nfft//4, :-1], mags[:,-1])\n",
    "\n",
    "# stacks to get -> (3, number_of_frames)\n",
    "Zxx = np.vstack((freq, times, mags))\n",
    "Zxx = Zxx.reshape(1, 1, Zxx.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model architecture\n",
    "\n",
    "class flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(flatten, self).__init__()\n",
    "        pass\n",
    "    def forward(self, out):\n",
    "        return torch.swapaxes(out.squeeze(), 0, 1).flatten()  \n",
    "    \n",
    "model = nn.Sequential(\n",
    "   nn.Conv2d(1, 20, kernel_size=(3, 20), stride=20, bias=True),\n",
    "   nn.Dropout2d(p=0.3),\n",
    "   nn.BatchNorm2d(20),\n",
    "   nn.Conv2d(20, 20, kernel_size=(1, 1), stride=1, bias=True),\n",
    "   flatten()\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-vegetable",
   "metadata": {},
   "source": [
    "### Results:\n",
    "+ The best train MSE loss we get is 1e-3, which unfortunately again is not enough.\n",
    "+ Increasing the architecture capacity doesn't seem to help, which I feel suggests that we are missing some information that are necessary to recreate the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-vacuum",
   "metadata": {},
   "source": [
    "### Approach 3: hacky training approach\n",
    "+ Based on the reassign_spectogram algorithm, I felt that what our model needs to learn aren't generalized features but one specific formulae that is common for all training data.\n",
    "    + Therefore instead of training on our Librispeech full dataset, I picked only couple of signals/samples to train our model. The learning rate was kept very low so that our model doesn't overfit that easily and the model architecture was slighly adapted to mitigate overfitting and increase model capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model architecture\n",
    "\n",
    "class flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(flatten, self).__init__()\n",
    "        pass\n",
    "    def forward(self, out):\n",
    "        return torch.swapaxes(out.squeeze(), 0, 1).flatten()  \n",
    "    \n",
    "model = nn.Sequential(\n",
    "   nn.Conv2d(1, 40, kernel_size=(3, 20), stride=20, bias=True),\n",
    "   nn.Dropout2d(p=0.8),\n",
    "   nn.BatchNorm2d(40),\n",
    "   nn.Conv2d(40, 20, kernel_size=(1, 1), stride=1, bias=True),\n",
    "   nn.Dropout2d(p=0.8),\n",
    "   nn.BatchNorm2d(20),\n",
    "   nn.Conv2d(20, 20, kernel_size=(1, 1), stride=1, bias=True),\n",
    "   flatten()\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-salem",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "+ The best train MSE without overfitting we achieved was 1e-4. The model was able to re-create signals when it was overfitted to achieve 1e-5+ MSE loss. Unfortunately, we still weren't able to recreate the signal without overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
